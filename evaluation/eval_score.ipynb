{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a205fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d81315",
   "metadata": {},
   "source": [
    "Evaluate Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = \"DeepWordBug\"\n",
    "\n",
    "# Dataset\n",
    "dataset_name = \"PeerRead_iclr_2017\"\n",
    "# dataset_name = 'AgentReview'\n",
    "\n",
    "# Model\n",
    "model_name = 'gpt-4o-mini'\n",
    "# model_name = 'Llama-3.3-70B'\n",
    "# model_name = \"gpt-4o\"\n",
    "# model_name = 'Mistral-small-3.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f9b6b7",
   "metadata": {},
   "source": [
    "Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad43aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_byline_path = f\"../result_EMNLP/{dataset_name}/{model_name}/{attack_name}/{attack_name}_ExplainFalse.jsonl\"\n",
    "output_file_dir = f\"result_score/{dataset_name}/{model_name}/{attack_name}/\"\n",
    "output_fig_dir = f\"result_score/{dataset_name}/{model_name}/{attack_name}/fig/\"\n",
    "\n",
    "if not os.path.exists(output_file_dir):\n",
    "    os.makedirs(output_file_dir)\n",
    "if not os.path.exists(output_fig_dir):\n",
    "    os.makedirs(output_fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e9ffe",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []\n",
    "with open(data_byline_path, \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        entry = json.loads(line.strip())\n",
    "        output_list.append(entry)\n",
    "        \n",
    "print(f\"[RESULT INFO] Dataset: {dataset_name}, Model: {model_name}, Attack: {attack_name}\")\n",
    "print(f\"[RESULT INFO] Total number of papers: {len(output_list)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3487b",
   "metadata": {},
   "source": [
    "Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "success = 0\n",
    "num_qyeries = 0\n",
    "score_shift_total = []\n",
    "original_score_total, attack_score_total = [], []\n",
    "t_test_pairs_total = []\n",
    "\n",
    "original_pos, original_neg = [], []\n",
    "attack_pos, attack_neg = [], []\n",
    "pos_shift, neg_shift = [], []\n",
    "\n",
    "for entry in output_list:\n",
    "    if entry[\"attack_success\"]:\n",
    "        success += 1\n",
    "    num_qyeries += entry[\"num_queries\"]\n",
    "\n",
    "    # prediction for original sample\n",
    "    tags_original = entry[\"original_output\"][0].keys()\n",
    "    tags_original_pos = len([tag for tag in tags_original if \"POSITIVE\" in tag])\n",
    "    tags_original_neg = len([tag for tag in tags_original if \"NEGATIVE\" in tag])\n",
    "    original_pos.append(tags_original_pos)\n",
    "    original_neg.append(tags_original_neg)\n",
    "\n",
    "    # prediction for attacked sample\n",
    "    tags_attack = entry[\"attacked_output\"][0].keys()\n",
    "    tags_attack_pos = len([tag for tag in tags_attack if \"POSITIVE\" in tag])\n",
    "    tags_attack_neg = len([tag for tag in tags_attack if \"NEGATIVE\" in tag])\n",
    "    attack_pos.append(tags_attack_pos)\n",
    "    attack_neg.append(tags_attack_neg)\n",
    "\n",
    "    # score & score shift\n",
    "    original_score_total.append(entry[\"original_score\"])\n",
    "    attack_score_total.append(entry[\"attacked_score\"])\n",
    "    score_shift_total.append(entry[\"score_shift\"])\n",
    "    pos_shift.append(tags_attack_pos - tags_original_pos)\n",
    "    neg_shift.append(tags_attack_neg - tags_original_neg)\n",
    "\n",
    "\n",
    "score_shift_total = np.array(score_shift_total)\n",
    "\n",
    "verbose_message = f\"\\\n",
    "Dataset: {dataset_name}, Model: {model_name}, Attack: {attack_name}\\n\\\n",
    "Total number of papers: {len(output_list)}\\n\\n\\\n",
    "[ASR] : \\n\\\n",
    "attack success rate: {(success/len(output_list)):.4f}, total: {len(output_list)}, success: {success}\\n\\\n",
    "[Score Prediction] : \\n\\\n",
    "average score shift in total: {(np.mean(score_shift_total)):.4f}\\n\\\n",
    "median score shift in total: {(np.median(score_shift_total)):.4f}\\n\\\n",
    "average score of original: {(np.mean(original_score_total)):.4f}\\n\\\n",
    "average score of attacked: {(np.mean(attack_score_total)):.4f}\\n\\n\\\n",
    "[Review Generation] : \\n\\\n",
    "average # of positive tag shift: {(np.mean(pos_shift)):.4f}\\n\\\n",
    "average # of negative tag shift: {(np.mean(neg_shift)):.4f}\\n\\\n",
    "average # of original tag : positive = {(np.mean(original_pos)):.4f}, negative = {(np.mean(original_neg)):.4f}\\n\\\n",
    "average # of attacked tag : positive = {(np.mean(attack_pos)):.4f}, negative = {(np.mean(attack_neg)):.4f}\\n\\\n",
    "median # of original tag : positive = {(np.median(original_pos)):.4f}, negative = {(np.median(original_neg)):.4f}\\n\\\n",
    "median # of attacked tag : positive = {(np.median(attack_pos)):.4f}, negative = {(np.median(attack_neg)):.4f}\\n\\n\\\n",
    "[Queries] : \\n\\\n",
    "average # of queries for each paper: {num_qyeries/len(output_list):.4f}\\n\\n\"\n",
    "\n",
    "print(verbose_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c262e6",
   "metadata": {},
   "source": [
    "Statistic Test (if the score differences are normally distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d236970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import wilcoxon, ttest_rel, shapiro, t\n",
    "\n",
    "differences = [x - y for x, y in zip(attack_score_total, original_score_total)]\n",
    "stat, p_value_normal = shapiro(differences)\n",
    "\n",
    "alpha = 0.05 # significance level\n",
    "confidence_level = 1 - alpha # confidence level\n",
    "\n",
    "confidence_interval_result = \"\" # string to store confidence interval\n",
    "\n",
    "# test if the score differences are significant\n",
    "if p_value_normal < alpha:\n",
    "    print(\"The differences are not normally distributed. Use Wilcoxon Signed-Rank Test.\")\n",
    "    test_type = \"Wilcoxon Signed-Rank Test\"\n",
    "    \n",
    "    stat_total, p_value_total = wilcoxon(\n",
    "        np.array(attack_score_total),\n",
    "        np.array(original_score_total),\n",
    "        alternative=\"greater\",\n",
    "    )\n",
    "    \n",
    "    # --- Confidence interval for Wilcoxon Signed-Rank Test ---\n",
    "    # Since the `wilcoxon` test is about whether the median difference is zero,\n",
    "    # a more robust approach is to calculate the confidence interval for the median difference.\n",
    "    # For Wilcoxon test, the standard confidence interval is based on the Hodges-Lehmann estimator.\n",
    "    # However, a more precise Hodges-Lehmann estimation usually requires manual implementation or specific packages.\n",
    "    # Here we provide an approximate method for calculating the confidence interval of the difference **median** as reference.\n",
    "\n",
    "    # Use bootstrap method to estimate confidence interval for median (more robust, but requires specifying iterations)\n",
    "    # If the data size is small and computing time is not sensitive, bootstrap method is recommended\n",
    "    \n",
    "    # Median estimate\n",
    "    hl_estimate = np.median(differences)\n",
    "\n",
    "    # Bootstrap CI (recommended)\n",
    "    n_bootstraps = 10000\n",
    "    alpha = 0.05\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "\n",
    "    medians = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        sample = rng.choice(differences, size=len(differences), replace=True)\n",
    "        medians.append(np.median(sample))\n",
    "\n",
    "    ci_lower = np.percentile(medians, 100 * (alpha / 2))\n",
    "    ci_upper = np.percentile(medians, 100 * (1 - alpha / 2))\n",
    "\n",
    "    confidence_interval_result = (\n",
    "        f\"Hodges-Lehmann estimate (median difference): {hl_estimate}\"\n",
    "        f\"\\nBootstrap 95% CI: ({ci_lower:.4f}, {ci_upper:.4f})\"\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"The differences are normally distributed. Use Paired T-Test.\")\n",
    "    test_type = \"Paired T-Test\"\n",
    "    \n",
    "    stat_total, p_value_total = ttest_rel(\n",
    "        np.array(attack_score_total),\n",
    "        np.array(original_score_total),\n",
    "        alternative=\"greater\",\n",
    "    )\n",
    "    \n",
    "    # --- Confidence interval for Paired T-Test ---\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences, ddof=1) # ddof=1 for sample standard deviation\n",
    "    n = len(differences)\n",
    "    se_diff = std_diff / np.sqrt(n)\n",
    "\n",
    "    df = n - 1\n",
    "    # Since we usually care about the two-sided confidence interval for the mean difference, even if the test is one-sided\n",
    "    t_critical = t.ppf(1 - alpha / 2, df) # critical value for two-tailed test\n",
    "\n",
    "    lower_bound = mean_diff - t_critical * se_diff\n",
    "    upper_bound = mean_diff + t_critical * se_diff\n",
    "\n",
    "    confidence_interval_result = (\n",
    "        f\"Confidence Interval for Mean Difference ({confidence_level*100:.0f}%): \"\n",
    "        f\"[{lower_bound:.2f}, {upper_bound:.2f}]\"\n",
    "    )\n",
    "\n",
    "print(f\"Test result: test statistic: {stat_total:.2f}, p-value: {p_value_total:.4e}\")\n",
    "print(confidence_interval_result) # print confidence interval result\n",
    "\n",
    "stat_verbose = \"There is a significant difference in total scores before and after attack.\" if p_value_total < alpha else \"There is no significant difference in total scores before and after attack.\"\n",
    "print(stat_verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test result: test statistic: {stat_total}, p-value: {p_value_total:.4e}\")\n",
    "alpha = 0.05\n",
    "stat_verbose = \"There is a significant difference in total scores before and after attack.\" if p_value_total < alpha else \"There is no significant difference in total scores before and after attack.\"\n",
    "print(stat_verbose)\n",
    "print(confidence_interval_result)\n",
    "\n",
    "\n",
    "with open(os.path.join(output_file_dir, \"attack_result.txt\"), \"w\") as f:\n",
    "    f.write(verbose_message)\n",
    "    f.write(\"[Statistic Test] : \\n\")\n",
    "    f.write(f\"Test type : {test_type}, (by shapiro) test statistic:{stat}, p-value:{p_value_normal:.4e}\\n\")\n",
    "    f.write(f\"{test_type} test result: test statistic: {stat_total}, p-value: {p_value_total:.4e}, significant:{p_value_total<alpha}\\n\")\n",
    "    f.write(confidence_interval_result + \"\\n\") # write confidence interval result to file\n",
    "    f.write(stat_verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d6c7f",
   "metadata": {},
   "source": [
    "[Optional] image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b182fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# 繪製攻擊前後數據的箱形圖\n",
    "plt.boxplot([original_score_total, attack_score_total], labels=[\"Original\", \"Attacked\"])\n",
    "plt.title(\"Boxplot of Scores Before and After Attack\")\n",
    "# plt.show()\n",
    "plt.savefig(os.path.join(output_fig_dir, f\"{attack_name}_boxplot.png\"))\n",
    "\n",
    "# 繪製差異的直方圖\n",
    "score_diff = [a - o for o, a in zip(original_score_total, attack_score_total)]\n",
    "min_diff = min(score_diff)\n",
    "max_diff = max(score_diff)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(\n",
    "    score_diff,\n",
    "    bins=range(min_diff, max_diff + 2),\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7,\n",
    "    align=\"left\",\n",
    ")\n",
    "# 設置 x 軸刻度，每個整數顯示\n",
    "plt.xticks(range(min_diff, max_diff + 1))\n",
    "plt.title(\"Distribution of Score Differences (Attacked - Original)\", fontsize=14)\n",
    "plt.xlabel(\"Score Difference (Attacked - Original)\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.grid(True)\n",
    "# plt.show()\n",
    "plt.savefig(os.path.join(output_fig_dir, f\"{attack_name}_distribution.png\"))\n",
    "\n",
    "\n",
    "aspects = [\n",
    "    \"NONE\",\n",
    "    \"SUMMARY\",\n",
    "    \"MOTIVATION POSITIVE\",\n",
    "    \"MOTIVATION NEGATIVE\",\n",
    "    \"SUBSTANCE POSITIVE\",\n",
    "    \"SUBSTANCE NEGATIVE\",\n",
    "    \"ORIGINALITY POSITIVE\",\n",
    "    \"ORIGINALITY NEGATIVE\",\n",
    "    \"SOUNDNESS POSITIVE\",\n",
    "    \"SOUNDNESS NEGATIVE\",\n",
    "    \"CLARITY POSITIVE\",\n",
    "    \"CLARITY NEGATIVE\",\n",
    "    \"REPLICABILITY POSITIVE\",\n",
    "    \"REPLICABILITY NEGATIVE\",\n",
    "    \"MEANINGFUL COMPARISON POSITIVE\",\n",
    "    \"MEANINGFUL COMPARISON NEGATIVE\",\n",
    "    \"IMPACT POSITIVE\",\n",
    "    \"IMPACT NEGATIVE\",\n",
    "]\n",
    "aspect_labels = {key: 0 for key in aspects}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "aspect label distribution in bar plot\n",
    "\"\"\"\n",
    "\n",
    "for entry in output_list:\n",
    "    for key in entry.keys():\n",
    "        if key == \"attacked_output\":\n",
    "            for tag in entry[key][0].keys():\n",
    "                tag = tag.replace(\"_\", \" \")\n",
    "                if tag in aspect_labels:\n",
    "                    aspect_labels[tag] += 1\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(aspect_labels.keys(), aspect_labels.values())\n",
    "plt.xlabel(\"Aspect Label\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Aspect Label Distribution\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(os.path.join(output_fig_dir, f\"{attack_name}_aspect_distribution.png\"))\n",
    "\n",
    "\"\"\"\n",
    "calculate the aspect sentiment shift  (我不確定我的理解有沒有錯)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if not os.path.exists(output_file_dir):\n",
    "    os.makedirs(output_file_dir)\n",
    "\n",
    "avg_aspect_score_changes = {\n",
    "    \"OVERALL\": 0,\n",
    "    \"SUBSTANCE\": 0,\n",
    "    \"APPROPRIATENESS\": 0,\n",
    "    \"COMPARISON\": 0,\n",
    "    \"CORRECTNESS\": 0,\n",
    "    \"ORIGINALITY\": 0,\n",
    "    \"CLARITY\": 0,\n",
    "    \"IMPACT\": 0,\n",
    "}\n",
    "\n",
    "with open(\n",
    "    os.path.join(output_file_dir, f\"{attack_name}_aspect_sentiment_shift.jsonl\"), \"w\"\n",
    ") as f:\n",
    "    for entry in output_list:\n",
    "        aspect_score_changes = {\n",
    "            \"OVERALL\": 0,\n",
    "            \"SUBSTANCE\": 0,\n",
    "            \"APPROPRIATENESS\": 0,\n",
    "            \"COMPARISON\": 0,\n",
    "            \"CORRECTNESS\": 0,\n",
    "            \"ORIGINALITY\": 0,\n",
    "            \"CLARITY\": 0,\n",
    "            \"IMPACT\": 0,\n",
    "        }\n",
    "        if \"original_output\" in entry and \"attacked_output\" in entry:\n",
    "            original_output_scores = entry[\"original_output\"][1]\n",
    "            attacked_output_scores = entry[\"attacked_output\"][1]\n",
    "            for tag in entry[\"original_output\"][1].keys():\n",
    "                tag = tag.replace(\"_\", \" \")\n",
    "                aspect_score_changes[tag] += (\n",
    "                    attacked_output_scores[tag] - original_output_scores[tag]\n",
    "                )\n",
    "                avg_aspect_score_changes[tag] += (\n",
    "                    attacked_output_scores[tag] - original_output_scores[tag]\n",
    "                )\n",
    "        output_data = {\n",
    "            \"paper_id\": entry[\"paper_id\"],\n",
    "            \"aspect_score_changes\": aspect_score_changes,\n",
    "        }\n",
    "\n",
    "        json.dump(output_data, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"\\naverage aspect sentiment shift :\")\n",
    "for key in avg_aspect_score_changes.keys():\n",
    "    avg_aspect_score_changes[key] /= len(output_list)\n",
    "    print(f\"{key} : {round(avg_aspect_score_changes[key], 6)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_reviewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
